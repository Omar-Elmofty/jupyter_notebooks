{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e674fe-a43d-42cf-89cd-06f35ce7676d",
   "metadata": {},
   "source": [
    "# CNN using Pytorch on the astar dataset\n",
    "Goal is to use CNNs to solve the supervised learning problem for finding the correct class label for the astar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111cffea-16eb-4708-8021-72b597765617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "303cbc18-f107-4069-abe9-2c0d3c7dca64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7.5205 seconds\n"
     ]
    }
   ],
   "source": [
    "# First let's load the dataset\n",
    "from datasets.astar_dataset import make_astar_dataset\n",
    "import time\n",
    "\n",
    "\n",
    "# Set the grid size here\n",
    "n, m = 5, 5  # grid size for the problem\n",
    "N = 100000     # Number of examples\n",
    "\n",
    "# Probability of existence of obstacle\n",
    "obstacle_probability = 0.3\n",
    "\n",
    "\n",
    "# Create the data set\n",
    "start = time.time()\n",
    "X, y = make_astar_dataset(N, n, m, obstacle_probability)\n",
    "print(f\"Execution time: {time.time() - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4374d02-80ab-4aaf-ad3f-2635658b4872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.391352</td>\n",
       "      <td>0.391352</td>\n",
       "      <td>0.391352</td>\n",
       "      <td>0.391352</td>\n",
       "      <td>0.429971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.188800       0.188800       0.188800       0.188800   \n",
       "std         0.391352       0.391352       0.391352       0.391352   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                   4  \n",
       "count  100000.000000  \n",
       "mean        0.244800  \n",
       "std         0.429971  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the statistics of each class label\n",
    "y_df = pd.DataFrame(y)  # Convert y to a pandas Series if it's not already\n",
    "y_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38a3636-aa39-44b4-8297-272a36ce807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from one_hot vector to integer indicies\n",
    "import numpy as np\n",
    "y = np.argmax(y, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0317174-a266-4dac-a212-3d56c9bf8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom torch dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "X_tensor = torch.from_numpy(X).float()\n",
    "y_tensor = torch.from_numpy(y).long()\n",
    "\n",
    "# Create a custom dataset class to retrieve the data\n",
    "class BinaryImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Create the dataset and dataloader classes\n",
    "\n",
    "dataset = BinaryImageDataset(X_tensor, y_tensor)\n",
    "trainloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf1f4c53-92ff-4c2d-8a50-e824c796366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5])\n",
      "right\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some of the images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# Visualizing the dataset\n",
    "\n",
    "classes = (\"up\", \"left\", \"down\", \"right\", \"no_path\")\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0]\n",
    "label = labels[0].item()\n",
    "\n",
    "print(img.shape)\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "imshow(img)\n",
    "\n",
    "print(classes[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a70ef2d1-7922-4ff2-bc3f-7dbb96aa9b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0168,  0.0272, -0.0851,  0.0229,  0.0068,  0.0022,  0.0250, -0.0115,\n",
       "          0.0126, -0.0576]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now create a network that can solve this problem\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AstarNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AstarNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 2)\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 16 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = AstarNetwork()\n",
    "net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bc8e12c-7364-4ca4-8622-3589774b1f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1999] loss: 0.20638796938219456\n",
      "[0, 3999] loss: 0.21065316307238527\n",
      "[0, 5999] loss: 0.20536157446226344\n",
      "[0, 7999] loss: 0.1989105144061473\n",
      "[0, 9999] loss: 0.19997391448260896\n",
      "[0, 11999] loss: 0.20906755476985744\n",
      "[0, 13999] loss: 0.20421540875558458\n",
      "[0, 15999] loss: 0.19820770329271956\n",
      "[0, 17999] loss: 0.2021563725722499\n",
      "[0, 19999] loss: 0.20677202260808417\n",
      "[0, 21999] loss: 0.20354850085637008\n",
      "[0, 23999] loss: 0.2031575512522568\n",
      "[1, 1999] loss: 0.20093943335754347\n",
      "[1, 3999] loss: 0.1991322250328974\n",
      "[1, 5999] loss: 0.19496676701679097\n",
      "[1, 7999] loss: 0.19449014881538415\n",
      "[1, 9999] loss: 0.20521756145048403\n",
      "[1, 11999] loss: 0.19739141212355207\n",
      "[1, 13999] loss: 0.2110900973192288\n",
      "[1, 15999] loss: 0.19913203360342596\n",
      "[1, 17999] loss: 0.20321195960312344\n",
      "[1, 19999] loss: 0.21026030896202247\n",
      "[1, 21999] loss: 0.19355191665762322\n",
      "[1, 23999] loss: 0.1962064299900194\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# Define the loss and the optimizer\n",
    "criterion = nn.CrossEntropyLoss() # The cross entropy loss for classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "for epoch in range(2): # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        # Zero gradient here is an important step\n",
    "        # Gradients are accumulated over a batch, if we don't reset the gradient here we will keep accumulating gradients\n",
    "        # making it impossible to train\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # Compute the gradients that will direct the learning\n",
    "        optimizer.step() # actually learn (one learning step)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # print every 2000 minibatches\n",
    "            print(f\"[{epoch}, {i}] loss: {running_loss / 2000}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30cf63c3-db83-4187-9b8b-d874f8df7f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 90.1\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Training accuracy: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3427141b-bd72-4aff-89df-4a80f124bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7.5404 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generate a test set and test on it\n",
    "# Create the data set\n",
    "\n",
    "N_test = 100000\n",
    "\n",
    "start = time.time()\n",
    "X_test, y_test = make_astar_dataset(N_test, n, m, obstacle_probability)\n",
    "print(f\"Execution time: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "test_dataset = BinaryImageDataset(X_test, y_test)\n",
    "testloader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c43e3f8-b9b9-4440-b052-3074d17089c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 86.173\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Testing accuracy: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1421e-9de9-4e42-81f5-a7b38d77a6db",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Test with different model architectures\n",
    "- Explore imitation learning techniques\n",
    "- Explore RL techniques\n",
    "Good article summarizing the different approaches that exist https://smartlabai.medium.com/a-brief-overview-of-imitation-learning-8a8a75c44a9c\n",
    "- Test with imitation learning https://imitation.readthedocs.io/en/latest/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
